\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{CubeSolves}
\citation{charades}
\citation{ava}
\citation{kinetics}
\citation{finegym}
\citation{hvu}
\citation{ng2019human}
\citation{action_sequence_movie}
\citation{r3d}
\@writefile{toc}{\contentsline {section}{\numberline {1}\hskip -1em.\nobreakspace  {}Introduction}{1}{section.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces The DeepCube dataset include the temporal labels and action labels for cube moves in the video. This figure shows two example movements, with transcription '$\text  {D}'$, $\text  {U}'$'.\relax }}{1}{figure.caption.1}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:recording_setup}{{1}{1}{The DeepCube dataset include the temporal labels and action labels for cube moves in the video. This figure shows two example movements, with transcription '$\text {D}'$, $\text {U}'$'.\relax }{figure.caption.1}{}}
\citation{cube_robotics}
\citation{cube_rl}
\citation{cube_rl}
\citation{cube_robotics}
\citation{hollywood2}
\citation{ucf101}
\citation{youtube8m}
\citation{charades}
\citation{activitynet}
\citation{ava}
\citation{sthsth}
\citation{epic_kitchen}
\citation{sadek2012fast}
\citation{stochastic}
\citation{lrcn}
\citation{ava}
\citation{better_ava}
\citation{i3d}
\citation{r3d}
\citation{faster_rcnn}
\citation{ss-tad}
\citation{g-tad}
\citation{ng2019human}
\citation{action_sequence_movie}
\@writefile{toc}{\contentsline {section}{\numberline {2}\hskip -1em.\nobreakspace  {}Related Work}{2}{section.2}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Action Recognition Datasets.}{2}{section*.2}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Action Classification and Detection.}{2}{section*.3}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3}\hskip -1em.\nobreakspace  {}Data}{2}{section.3}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Format and Definitions.}{2}{section*.4}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Collection Pipeline.}{2}{section*.5}\protected@file@percent }
\citation{resnet}
\citation{r3d}
\citation{resnet}
\citation{r3d}
\citation{resnet}
\@writefile{toc}{\contentsline {paragraph}{Dataset Statistics.}{3}{section*.6}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Temporal Localization.}{3}{section*.7}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4}\hskip -1em.\nobreakspace  {}Methods}{3}{section.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}\hskip -1em.\nobreakspace  {}3D Residual Convolutional Network}{3}{subsection.4.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Feature extractors, space-wise dimension not depicted for frames, highlighted frames on top convolves to same-colored frame at bottom. Left: 3D convolutional feature extractor; Right: 2D convolutional feature extractor\relax }}{3}{figure.caption.8}\protected@file@percent }
\newlabel{fig:3dconv}{{2}{3}{Feature extractors, space-wise dimension not depicted for frames, highlighted frames on top convolves to same-colored frame at bottom. Left: 3D convolutional feature extractor; Right: 2D convolutional feature extractor\relax }{figure.caption.8}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}\hskip -1em.\nobreakspace  {}3D Convolutional Sequence Recognizer}{3}{subsection.4.2}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{3D Convolutional Feature Extractor.}{3}{section*.9}\protected@file@percent }
\citation{lrcn}
\citation{ctc}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Action recognizer models, channel-wise dimension not depicted for frames. Left: 2D convolutional action recognizer; Right: LRCN and 3D-LRCN\relax }}{4}{figure.caption.11}\protected@file@percent }
\newlabel{fig:armodels}{{3}{4}{Action recognizer models, channel-wise dimension not depicted for frames. Left: 2D convolutional action recognizer; Right: LRCN and 3D-LRCN\relax }{figure.caption.11}{}}
\@writefile{toc}{\contentsline {paragraph}{Time-distributed Feed-forward Network.}{4}{section*.10}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3}\hskip -1em.\nobreakspace  {}LRCN Sequence Recognizer}{4}{subsection.4.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4}\hskip -1em.\nobreakspace  {}3D-LRCN Sequence Recognizer}{4}{subsection.4.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.5}\hskip -1em.\nobreakspace  {}Training Sequence Recognizer Models}{4}{subsection.4.5}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Connectionist Temporal Classification (CTC).}{4}{section*.12}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Beam Search at Inference.}{4}{section*.13}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.6}\hskip -1em.\nobreakspace  {}Data Spatio-temporal Augmentation}{4}{subsection.4.6}\protected@file@percent }
\newlabel{section:data-aug}{{4.6}{4}{\hskip -1em.~Data Spatio-temporal Augmentation}{subsection.4.6}{}}
\citation{activitynet}
\citation{epic_kitchen}
\citation{thumos}
\@writefile{toc}{\contentsline {paragraph}{Spatial Augmentation.}{5}{section*.14}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Temporal Augmentation.}{5}{section*.15}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {5}\hskip -1em.\nobreakspace  {}Experiment}{5}{section.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1}\hskip -1em.\nobreakspace  {}Video Classification}{5}{subsection.5.1}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Hyperparameters}{5}{section*.16}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Evaluation Metric.}{5}{section*.17}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Results.}{5}{section*.18}\protected@file@percent }
\citation{action_sequence_movie}
\citation{ng2019human}
\citation{kingma2014adam}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Results for multi-class action classification\relax }}{6}{table.caption.19}\protected@file@percent }
\newlabel{tab:resnet}{{1}{6}{Results for multi-class action classification\relax }{table.caption.19}{}}
\newlabel{da_results}{{1}{6}{Results for multi-class action classification\relax }{table.caption.19}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2}\hskip -1em.\nobreakspace  {}Action Sequence Stream Recognition}{6}{subsection.5.2}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces Precision-Speed Trade-off vs. Beam Width\relax }}{6}{table.caption.24}\protected@file@percent }
\newlabel{tab:beam}{{2}{6}{Precision-Speed Trade-off vs. Beam Width\relax }{table.caption.24}{}}
\@writefile{toc}{\contentsline {paragraph}{Hyperparameters and Model Selection.}{6}{section*.20}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Evaluation Metric.}{6}{section*.21}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Results.}{6}{section*.22}\protected@file@percent }
\@writefile{toc}{\contentsline {subparagraph}{Effect of Beam Widths}{6}{table.caption.24}\protected@file@percent }
\citation{simonyan2013deep}
\@writefile{lot}{\contentsline {table}{\numberline {3}{\ignorespaces Dev EDPF vs. Data Augmentation\relax }}{7}{table.caption.26}\protected@file@percent }
\newlabel{tab:aug}{{3}{7}{Dev EDPF vs. Data Augmentation\relax }{table.caption.26}{}}
\@writefile{lot}{\contentsline {table}{\numberline {4}{\ignorespaces All Sequence Recognizer EDPF\relax }}{7}{table.caption.28}\protected@file@percent }
\newlabel{tab:all-seq-recog}{{4}{7}{All Sequence Recognizer EDPF\relax }{table.caption.28}{}}
\@writefile{toc}{\contentsline {subparagraph}{Effect of Data Augmentation}{7}{section*.25}\protected@file@percent }
\@writefile{toc}{\contentsline {subparagraph}{All Sequence Recognizer Model Performance}{7}{section*.27}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3}\hskip -1em.\nobreakspace  {}Model Explainability}{7}{subsection.5.3}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Saliency Over a Clip.}{7}{section*.29}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Typical saliency map for video clips near the predicted moves B (back c.w.), L (left c.w.) and U' (upper c.c.w.).\relax }}{8}{figure.caption.30}\protected@file@percent }
\newlabel{fig:saliency}{{4}{8}{Typical saliency map for video clips near the predicted moves B (back c.w.), L (left c.w.) and U' (upper c.c.w.).\relax }{figure.caption.30}{}}
\@writefile{toc}{\contentsline {paragraph}{Frame-by-frame saliency.}{8}{section*.31}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Frame-by-frame saliency maps for sequence recognizer models over a clip. Each row corresponds to a resulting frame prediction, and the columns correspond to what source frames influence the decision of that row. Models are 3DCNN, LRCN, 3DLRCN from left to right.\relax }}{8}{figure.caption.32}\protected@file@percent }
\newlabel{fig:saliency-fbf}{{5}{8}{Frame-by-frame saliency maps for sequence recognizer models over a clip. Each row corresponds to a resulting frame prediction, and the columns correspond to what source frames influence the decision of that row. Models are 3DCNN, LRCN, 3DLRCN from left to right.\relax }{figure.caption.32}{}}
\@writefile{toc}{\contentsline {section}{\numberline {6}\hskip -1em.\nobreakspace  {}Conclusion}{8}{section.6}\protected@file@percent }
\bibstyle{ieee_fullname}
\bibdata{egbib}
\bibcite{CubeSolves}{1}
\bibcite{youtube8m}{2}
\bibcite{cube_robotics}{3}
\bibcite{ss-tad}{4}
\bibcite{activitynet}{5}
\bibcite{i3d}{6}
\bibcite{stochastic}{7}
\bibcite{epic_kitchen}{8}
\bibcite{hvu}{9}
\bibcite{lrcn}{10}
\bibcite{better_ava}{11}
\bibcite{sthsth}{12}
\bibcite{ctc}{13}
\bibcite{ava}{14}
\bibcite{r3d}{15}
\bibcite{resnet}{16}
\bibcite{thumos}{17}
\bibcite{kinetics}{18}
\bibcite{kingma2014adam}{19}
\bibcite{action_sequence_movie}{20}
\bibcite{hollywood2}{21}
\bibcite{cube_rl}{22}
\bibcite{ng2019human}{23}
\bibcite{faster_rcnn}{24}
\bibcite{sadek2012fast}{25}
\bibcite{finegym}{26}
\bibcite{charades}{27}
\bibcite{simonyan2013deep}{28}
\bibcite{ucf101}{29}
\bibcite{g-tad}{30}
\@writefile{toc}{\contentsline {section}{\numberline {A}\hskip -1em.\nobreakspace  {}Model Full Specifications}{11}{appendix.A}\protected@file@percent }
\newlabel{appendix:model-spec}{{A}{11}{\hskip -1em.~Model Full Specifications}{appendix.A}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {A.1}\hskip -1em.\nobreakspace  {}3D Convolutional Sequence Recognizer}{11}{subsection.A.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {A.2}\hskip -1em.\nobreakspace  {}LRCN Sequence Recognizer}{11}{subsection.A.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {A.3}\hskip -1em.\nobreakspace  {}3D LRCN Sequence Recognizer}{12}{subsection.A.3}\protected@file@percent }
